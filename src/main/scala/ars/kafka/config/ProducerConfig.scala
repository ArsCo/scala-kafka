/*
 * Copyright 2018 Arsen Ibragimov (ars)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 *  Unless required by applicable law or agreed to in writing, software
 *  distributed under the License is distributed on an "AS IS" BASIS,
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package ars.kafka.config

import ars.kafka.config.Serializers.ByteBufferSerializers
import ars.kafka.config.Server.DefaultLocalServer

/** Kafka producer configuration.
  *
  * @author Arsen Ibragimov (ars)
  * @since 0.0.1
  */
trait ProducerConfig extends CommonConfig {

  /**
    * Gets producer serializers.
    *
    * @return the serializers (non-null)
    */
  def serializers: Serializers

  /**
    * Gets producer `bootstrap.servers` parameter.
    *
    * @return the bootstrap servers (non-blank seq of non-blank elements)
    */
  def bootstrapServers: Seq[Server]

  /**
    * Gets producer `acks` parameter.
    *
    * @return the number of acknowledgments the producer requires the leader to have
    *         received before considering a request complete (non-null option of non-null)
    */
  def asks: Option[ProducerAck] = None

  /**
    * Gets producer `buffer.memory` parameter.
    *
    * @return the total bytes of memory the producer can use to buffer records waiting
    *         to be sent to the server (non-null option of non-negative number).
    */
  def memoryBuffer: Option[Long] = None

  /**
    * Gets producer `compression.type` parameter.
    *
    * @return the compression type for all data generated by the producer. (non-null option of non-null).
    */
  def compressionType: Option[CompressionType] = None

  /**
    * Gets producer `retries` parameter.
    *
    * @return the number of resends. (non-null option of non-negative number).
    */
  def retries: Option[Int] = None

  /**
    * Gets producer `enable.idempotence` parameter.
    * When set to `true`, the producer will ensure that exactly one copy of each message is written in the stream.
    *
    * @return the idempotance (non-null option)
    */
  def idempotence: Option[Boolean] = None

  /**
    * Gets producer `ssl.key.password` parameter.
    *
    * @return the password of the private key in the key store file.
    *         This is optional for client (non-null option of non-null)
    */
  def sslKeyPassword: Option[String] = None

  /**
    * Gets producer `ssl.keystore.location` and `ssl.keystore.password` parameters.
    *
    * @return the location of the key store file and
    *         the store password for the key store file (non-null option of non-null)
    */
  def sslKeystore: Option[Ssl] = None

  /**
    * Gets producer `ssl.truststore.location` and `ssl.truststore.password` parameters.
    *
    * @return the location of the trust store file and
    *         the store password for the trust store file (non-null option of non-null)
    */
  def sslTruststore: Option[Ssl] = None

  /**
    * Gets producer `batch.size` parameter.
    *
    * @return default batch size in bytes. (non-null option of non-negative)
    */
  def batchSize: Option[Int] = None

  /**
    * Gets producer `client.id` parameter.
    *
    * @return // TODO
    */
  def clientId: Option[String] = None

  /** @inheritdoc */
  override def all: Map[String, Any] = {

    val required = toMap(serializers) ++ toMap(bootstrapServers :_*)

    val optional = optionalsToMap(
      ("acks", asks),
      ("buffer.memory", memoryBuffer),
      ("compression.type", compressionType),
      ("retries", retries),
      ("enable.idempotence", idempotence),
      ("ssl.key.password", sslKeyPassword),
      ("batch.size", batchSize),
      ("client.id", clientId)
    ) ++ toKeystoreMap(sslKeystore) ++ toTruststoreMap(sslTruststore)

    super.all ++ required ++ optional
  }

  private def toMap(serializers: Serializers): Map[String, Any] = {
    Map(
      "key.serializer" -> serializers.key,
      "value.serializer" -> serializers.value
    )
  }

  private def toKeystoreMap(keystore: Option[Ssl]): Map[String, Any] = {
    keystore.map { case Ssl(location, password) =>
      Map(
        "ssl.keystore.location" -> location,
        "ssl.keystore.password" -> password
      )
    }.getOrElse(Map())
  }

  private def toTruststoreMap(truststore: Option[Ssl]): Map[String, Any] = {
    truststore.map { case Ssl(location, password) =>
      Map(
        "ssl.truststore.location" -> location,
        "ssl.truststore.password" -> password
      )
    }.getOrElse(Map())
  }
}

object ProducerConfig {

  /**
    * Creates local Kafka producer configuration.
    *
    * @param serializers the serializers (non-null).
    *                    By default it uses binary serializers for both key and value.
    * @param bootstrapServers the bootstrap servers (non-blank)
    *                         By default it uses `localhost:9092`
    *
    * @throws IllegalArgumentException if any argument is invalid
    *
    * @return the new instance of configuration.
    */
  def defaultLocal(
      serializers: Serializers = ByteBufferSerializers,
      bootstrapServers: Seq[Server] = Seq(DefaultLocalServer)
  ): ProducerConfig = {
    DefaultProducerConfig(serializers, bootstrapServers)
  }
}
